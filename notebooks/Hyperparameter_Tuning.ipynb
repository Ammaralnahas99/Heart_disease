{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f1b715a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.6 Hyperparameter Tuning - Model Optimization\n",
    "# ===============================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import joblib, os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b4b31d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Data loaded successfully for Feature Selection.\n",
      "Data shape: (303, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  sex   cp  trestbps   chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0  63.0  1.0  1.0     145.0  233.0  1.0      2.0    150.0    0.0      2.3   \n",
       "1  67.0  1.0  4.0     160.0  286.0  0.0      2.0    108.0    1.0      1.5   \n",
       "2  67.0  1.0  4.0     120.0  229.0  0.0      2.0    129.0    1.0      2.6   \n",
       "3  37.0  1.0  3.0     130.0  250.0  0.0      0.0    187.0    0.0      3.5   \n",
       "4  41.0  0.0  2.0     130.0  204.0  0.0      2.0    172.0    0.0      1.4   \n",
       "\n",
       "   slope   ca  thal  target  \n",
       "0    3.0  0.0   6.0       0  \n",
       "1    2.0  3.0   3.0       1  \n",
       "2    2.0  2.0   7.0       1  \n",
       "3    3.0  0.0   3.0       0  \n",
       "4    1.0  0.0   3.0       0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Step 1: Load Dataset ---\n",
    "try:\n",
    "    df = pd.read_csv(r\"C:\\Users\\USER\\python\\heart_data_clean.csv\")\n",
    "    print(\" Data loaded successfully for Feature Selection.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"'heart_data_clean.csv' not found\")\n",
    "    raise\n",
    "\n",
    "print(f\"Data shape: {df.shape}\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8fda2348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (303, 13)\n",
      "Target distribution:\n",
      " target\n",
      "0    164\n",
      "1    139\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# --- Step 2: Split into Features and Target ---\n",
    "X = df.drop(\"target\", axis=1)   \n",
    "y = df[\"target\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Features shape:\", X.shape)\n",
    "print(\"Target distribution:\\n\", y.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c2e001f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 3: Define Models and Hyperparameter Grids ---\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf_params = {\n",
    "    \"n_estimators\": [50, 100, 200],\n",
    "    \"max_depth\": [None, 5, 10],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Support Vector Machine\n",
    "svm = SVC(probability=True, random_state=42)\n",
    "svm_params = {\n",
    "    \"C\": [0.1, 1, 10],\n",
    "    \"kernel\": [\"linear\", \"rbf\", \"poly\"],\n",
    "    \"gamma\": [\"scale\", \"auto\"]\n",
    "}\n",
    "\n",
    "# Logistic Regression\n",
    "logreg = LogisticRegression(max_iter=1000, random_state=42)\n",
    "log_params = {\n",
    "    \"C\": [0.01, 0.1, 1, 10],\n",
    "    \"penalty\": [\"l1\", \"l2\"],\n",
    "    \"solver\": [\"liblinear\", \"lbfgs\"]   \n",
    "}\n",
    "\n",
    "# Model list\n",
    "models = [\n",
    "    (\"RandomForest\", rf, rf_params),\n",
    "    (\"SVM\", svm, svm_params),\n",
    "    (\"LogisticRegression\", logreg, log_params)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a2a8cc0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Fast RandomizedSearchCV for: RandomForest\n",
      "‚úÖ Best parameters for RandomForest: {'n_estimators': 100, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_depth': None}\n",
      "\n",
      "üîç Fast RandomizedSearchCV for: SVM\n",
      "‚úÖ Best parameters for SVM: {'kernel': 'linear', 'gamma': 'scale', 'C': 0.1}\n",
      "\n",
      "üîç Fast RandomizedSearchCV for: LogisticRegression\n",
      "‚úÖ Best parameters for LogisticRegression: {'solver': 'liblinear', 'penalty': 'l2', 'C': 1}\n",
      "\n",
      "üèÜ Overall best model: RandomForest with Accuracy=0.8689\n",
      "‚úÖ Final best model saved as final_model.pkl\n",
      "\n",
      "‚úÖ Hyperparameter tuning completed with RandomizedSearchCV.\n"
     ]
    }
   ],
   "source": [
    "# --- Step 4: Randomized Hyperparameter Tuning (Fast Version) ---\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "best_models = []\n",
    "overall_best_score = 0\n",
    "overall_best_model = None\n",
    "overall_best_name = \"\"\n",
    "\n",
    "# --- Define models and parameter grids ---\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_params = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 5, 10],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "svm_model = SVC(probability=True, random_state=42)\n",
    "svm_params = {\n",
    "    'C': [0.1, 1, 10],         # reduced values\n",
    "    'kernel': ['linear', 'rbf'],  # faster kernels\n",
    "    'gamma': ['scale']         # only 'scale'\n",
    "}\n",
    "\n",
    "log_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "log_params = {\n",
    "    'C': [0.01, 0.1, 1, 10],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['liblinear']    # supports both l1 and l2\n",
    "}\n",
    "\n",
    "models = [\n",
    "    ('RandomForest', rf_model, rf_params),\n",
    "    ('SVM', svm_model, svm_params),\n",
    "    ('LogisticRegression', log_model, log_params)\n",
    "]\n",
    "\n",
    "# --- Loop through models ---\n",
    "for name, model, params in models:\n",
    "    print(f\"\\nüîç Fast RandomizedSearchCV for: {name}\")\n",
    "    \n",
    "    rand_search = RandomizedSearchCV(\n",
    "        estimator=model,\n",
    "        param_distributions=params,\n",
    "        n_iter=5,               # max 5 random trials\n",
    "        cv=3,                   # 3-fold CV for speed\n",
    "        scoring='accuracy',\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    rand_search.fit(X_train, y_train)\n",
    "    print(f\"‚úÖ Best parameters for {name}: {rand_search.best_params_}\")\n",
    "    \n",
    "    y_pred = rand_search.predict(X_test)\n",
    "    \n",
    "    # --- Evaluate metrics ---\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    \n",
    "    best_models.append({\n",
    "        'Model': name,\n",
    "        'Best_Params': rand_search.best_params_,\n",
    "        'Accuracy': acc,\n",
    "        'Precision': prec,\n",
    "        'Recall': rec,\n",
    "        'F1_Score': f1\n",
    "    })\n",
    "    \n",
    "    # Save each best model\n",
    "    joblib.dump(rand_search.best_estimator_, f\"results/{name}_best_model.pkl\")\n",
    "    \n",
    "    # Track overall best\n",
    "    if acc > overall_best_score:\n",
    "        overall_best_score = acc\n",
    "        overall_best_model = rand_search.best_estimator_\n",
    "        overall_best_name = name\n",
    "\n",
    "# --- Save results ---\n",
    "results_df = pd.DataFrame(best_models)\n",
    "results_df.to_csv(\"results/hyperparameter_tuning_results.csv\", index=False)\n",
    "\n",
    "# --- Save final best model ---\n",
    "if overall_best_model is not None:\n",
    "    joblib.dump(overall_best_model, \"results/final_model.pkl\")\n",
    "    print(f\"\\nüèÜ Overall best model: {overall_best_name} with Accuracy={overall_best_score:.4f}\")\n",
    "    print(\"‚úÖ Final best model saved as final_model.pkl\")\n",
    "\n",
    "print(\"\\n‚úÖ Hyperparameter tuning completed with RandomizedSearchCV.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cc8eb6fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Hyperparameter Tuning Results:\n",
      "                Model                                        Best_Params  \\\n",
      "0        RandomForest  {'n_estimators': 100, 'min_samples_split': 5, ...   \n",
      "1                 SVM   {'kernel': 'linear', 'gamma': 'scale', 'C': 0.1}   \n",
      "2  LogisticRegression   {'solver': 'liblinear', 'penalty': 'l2', 'C': 1}   \n",
      "\n",
      "   Accuracy  Precision    Recall  F1_Score  \n",
      "0  0.868852   0.876625  0.868852  0.868993  \n",
      "1  0.852459   0.857060  0.852459  0.852697  \n",
      "2  0.868852   0.876625  0.868852  0.868993  \n",
      "\n",
      " Best Model: RandomForest with Accuracy=0.8689\n",
      "Final best model saved at '../models/best_expected_model.pkl'\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame(best_models)\n",
    "results_df.to_csv(\"C:/Users/USER/python/hyperparameter_tuning_final.csv\", index=False)\n",
    "print(\"\\n Hyperparameter Tuning Results:\")\n",
    "print(results_df)\n",
    "\n",
    "# Save final best model\n",
    "if overall_best_model is not None:\n",
    "    os.makedirs(\"../models\", exist_ok=True)\n",
    "    joblib.dump(overall_best_model, \"../models/final_model.pkl\")\n",
    "    print(f\"\\n Best Model: {overall_best_name} with Accuracy={overall_best_score:.4f}\")\n",
    "    print(\"Final best model saved at '../models/best_expected_model.pkl'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
